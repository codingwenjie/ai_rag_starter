#!/usr/bin/env python3
"""RAGç³»ç»Ÿæ¼”ç¤ºè„šæœ¬

å±•ç¤ºå¦‚ä½•ä½¿ç”¨RAGç³»ç»Ÿè¿›è¡Œæ–‡æ¡£é—®ç­”ï¼ŒåŒ…æ‹¬ï¼š
1. æ–‡æ¡£ä¸Šä¼ å’Œå¤„ç†
2. åŸºç¡€é—®ç­”æŸ¥è¯¢
3. å¯¹è¯å¼é—®ç­”
4. ç›¸ä¼¼åº¦æœç´¢

ä½¿ç”¨æ–¹æ³•:
    python examples/rag_demo.py
"""

import os
import sys
import asyncio
import tempfile
from pathlib import Path
from typing import List, Dict, Any

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(str(Path(__file__).parent.parent))

try:
    from services.rag.rag_service import RAGService, RAGConfig
    from services.rag.retrieval_qa import create_qa_component
    from services.rag.document_loader import DocumentLoader
    from services.rag.text_splitter import SmartTextSplitter
except ImportError as e:
    print(f"å¯¼å…¥é”™è¯¯: {e}")
    print("è¯·ç¡®ä¿å·²å®‰è£…æ‰€éœ€ä¾èµ–åŒ…")
    sys.exit(1)

class RAGDemo:
    """RAGç³»ç»Ÿæ¼”ç¤ºç±»"""
    
    def __init__(self):
        """åˆå§‹åŒ–æ¼”ç¤ºç¯å¢ƒ"""
        self.rag_service = None
        self.qa_components = {}
        self.collection_name = "demo_collection"
        
    def setup_rag_service(self):
        """è®¾ç½®RAGæœåŠ¡"""
        print("ğŸ”§ åˆå§‹åŒ–RAGæœåŠ¡...")
        
        # åˆ›å»ºRAGé…ç½®
        config = RAGConfig(
            chunk_size=800,
            chunk_overlap=100,
            embedding_model="text-embedding-ada-002",
            llm_model="gpt-3.5-turbo",
            temperature=0.1,
            max_tokens=1000,
            retrieval_k=4
        )
        
        # åˆå§‹åŒ–RAGæœåŠ¡
        self.rag_service = RAGService(config)
        print("âœ… RAGæœåŠ¡åˆå§‹åŒ–å®Œæˆ")
        
    def create_sample_documents(self) -> List[str]:
        """åˆ›å»ºç¤ºä¾‹æ–‡æ¡£
        
        Returns:
            List[str]: ç¤ºä¾‹æ–‡æ¡£æ–‡ä»¶è·¯å¾„åˆ—è¡¨
        """
        print("ğŸ“ åˆ›å»ºç¤ºä¾‹æ–‡æ¡£...")
        
        # ç¤ºä¾‹æ–‡æ¡£å†…å®¹
        documents = {
            "ai_introduction.md": """
# äººå·¥æ™ºèƒ½ç®€ä»‹

äººå·¥æ™ºèƒ½ï¼ˆArtificial Intelligenceï¼ŒAIï¼‰æ˜¯è®¡ç®—æœºç§‘å­¦çš„ä¸€ä¸ªåˆ†æ”¯ï¼Œè‡´åŠ›äºåˆ›å»ºèƒ½å¤Ÿæ‰§è¡Œé€šå¸¸éœ€è¦äººç±»æ™ºèƒ½çš„ä»»åŠ¡çš„ç³»ç»Ÿã€‚

## ä¸»è¦é¢†åŸŸ

### æœºå™¨å­¦ä¹ 
æœºå™¨å­¦ä¹ æ˜¯AIçš„æ ¸å¿ƒæŠ€æœ¯ä¹‹ä¸€ï¼Œé€šè¿‡ç®—æ³•è®©è®¡ç®—æœºä»æ•°æ®ä¸­å­¦ä¹ æ¨¡å¼ï¼Œè€Œæ— éœ€æ˜ç¡®ç¼–ç¨‹ã€‚

### æ·±åº¦å­¦ä¹ 
æ·±åº¦å­¦ä¹ æ˜¯æœºå™¨å­¦ä¹ çš„å­é›†ï¼Œä½¿ç”¨å¤šå±‚ç¥ç»ç½‘ç»œæ¥æ¨¡æ‹Ÿäººè„‘çš„å·¥ä½œæ–¹å¼ã€‚

### è‡ªç„¶è¯­è¨€å¤„ç†
è‡ªç„¶è¯­è¨€å¤„ç†ï¼ˆNLPï¼‰ä½¿è®¡ç®—æœºèƒ½å¤Ÿç†è§£ã€è§£é‡Šå’Œç”Ÿæˆäººç±»è¯­è¨€ã€‚

## åº”ç”¨åœºæ™¯
- å›¾åƒè¯†åˆ«
- è¯­éŸ³è¯†åˆ«
- æ¨èç³»ç»Ÿ
- è‡ªåŠ¨é©¾é©¶
- åŒ»ç–—è¯Šæ–­
""",
            "rag_technology.md": """
# RAGæŠ€æœ¯è¯¦è§£

æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRetrieval-Augmented Generationï¼ŒRAGï¼‰æ˜¯ä¸€ç§ç»“åˆä¿¡æ¯æ£€ç´¢å’Œæ–‡æœ¬ç”Ÿæˆçš„AIæŠ€æœ¯ã€‚

## RAGå·¥ä½œåŸç†

1. **æ–‡æ¡£ç´¢å¼•**: å°†çŸ¥è¯†åº“æ–‡æ¡£è½¬æ¢ä¸ºå‘é‡è¡¨ç¤ºå¹¶å­˜å‚¨
2. **æŸ¥è¯¢æ£€ç´¢**: æ ¹æ®ç”¨æˆ·é—®é¢˜æ£€ç´¢ç›¸å…³æ–‡æ¡£ç‰‡æ®µ
3. **ä¸Šä¸‹æ–‡å¢å¼º**: å°†æ£€ç´¢åˆ°çš„ä¿¡æ¯ä½œä¸ºä¸Šä¸‹æ–‡æä¾›ç»™è¯­è¨€æ¨¡å‹
4. **ç­”æ¡ˆç”Ÿæˆ**: åŸºäºä¸Šä¸‹æ–‡ç”Ÿæˆå‡†ç¡®çš„å›ç­”

## æŠ€æœ¯ä¼˜åŠ¿

- **çŸ¥è¯†æ›´æ–°**: å¯ä»¥å®æ—¶æ›´æ–°çŸ¥è¯†åº“ï¼Œæ— éœ€é‡æ–°è®­ç»ƒæ¨¡å‹
- **å¯è§£é‡Šæ€§**: å¯ä»¥è¿½æº¯ç­”æ¡ˆæ¥æºï¼Œæé«˜å¯ä¿¡åº¦
- **é¢†åŸŸé€‚åº”**: å®¹æ˜“é€‚åº”ç‰¹å®šé¢†åŸŸçš„çŸ¥è¯†
- **æˆæœ¬æ•ˆç›Š**: ç›¸æ¯”è®­ç»ƒå¤§æ¨¡å‹ï¼Œæˆæœ¬æ›´ä½

## æ ¸å¿ƒç»„ä»¶

### æ–‡æ¡£åŠ è½½å™¨
è´Ÿè´£ä»å„ç§æ ¼å¼ï¼ˆPDFã€Wordã€HTMLç­‰ï¼‰ä¸­æå–æ–‡æœ¬å†…å®¹ã€‚

### æ–‡æœ¬åˆ‡åˆ†å™¨
å°†é•¿æ–‡æ¡£åˆ‡åˆ†ä¸ºé€‚åˆæ£€ç´¢çš„æ–‡æœ¬å—ï¼Œä¿æŒè¯­ä¹‰å®Œæ•´æ€§ã€‚

### å‘é‡å­˜å‚¨
ä½¿ç”¨åµŒå…¥æ¨¡å‹å°†æ–‡æœ¬è½¬æ¢ä¸ºå‘é‡ï¼Œå¹¶å»ºç«‹é«˜æ•ˆçš„æ£€ç´¢ç´¢å¼•ã€‚

### æ£€ç´¢å™¨
æ ¹æ®æŸ¥è¯¢å‘é‡æ‰¾åˆ°æœ€ç›¸å…³çš„æ–‡æ¡£ç‰‡æ®µã€‚

### ç”Ÿæˆå™¨
åŸºäºæ£€ç´¢åˆ°çš„ä¸Šä¸‹æ–‡ç”Ÿæˆæœ€ç»ˆç­”æ¡ˆã€‚
""",
            "langchain_guide.md": """
# LangChainä½¿ç”¨æŒ‡å—

LangChainæ˜¯ä¸€ä¸ªç”¨äºæ„å»ºåŸºäºè¯­è¨€æ¨¡å‹åº”ç”¨çš„æ¡†æ¶ï¼Œç‰¹åˆ«é€‚åˆå¼€å‘RAGç³»ç»Ÿã€‚

## æ ¸å¿ƒæ¦‚å¿µ

### é“¾ï¼ˆChainsï¼‰
é“¾æ˜¯LangChainçš„æ ¸å¿ƒæ¦‚å¿µï¼Œç”¨äºç»„åˆå¤šä¸ªç»„ä»¶æ¥å®Œæˆå¤æ‚ä»»åŠ¡ã€‚

### æ–‡æ¡£åŠ è½½å™¨ï¼ˆDocument Loadersï¼‰
LangChainæä¾›äº†å¤šç§æ–‡æ¡£åŠ è½½å™¨ï¼Œæ”¯æŒPDFã€CSVã€HTMLç­‰æ ¼å¼ã€‚

### æ–‡æœ¬åˆ†å‰²å™¨ï¼ˆText Splittersï¼‰
ç”¨äºå°†é•¿æ–‡æ¡£åˆ†å‰²ä¸ºè¾ƒå°çš„å—ï¼Œä¾¿äºå‘é‡åŒ–å’Œæ£€ç´¢ã€‚

### å‘é‡å­˜å‚¨ï¼ˆVector Storesï¼‰
æ”¯æŒå¤šç§å‘é‡æ•°æ®åº“ï¼Œå¦‚FAISSã€Chromaã€Pineconeç­‰ã€‚

## RAGå®ç°ç¤ºä¾‹

```python
from langchain.chains import RetrievalQA
from langchain.llms import OpenAI
from langchain.vectorstores import FAISS

# åˆ›å»ºæ£€ç´¢é—®ç­”é“¾
qa_chain = RetrievalQA.from_chain_type(
    llm=OpenAI(),
    chain_type="stuff",
    retriever=vector_store.as_retriever()
)

# æ‰§è¡Œé—®ç­”
result = qa_chain.run("ä»€ä¹ˆæ˜¯RAGæŠ€æœ¯ï¼Ÿ")
```

## æœ€ä½³å®è·µ

1. **åˆç†çš„æ–‡æœ¬åˆ†å—**: é€‰æ‹©é€‚å½“çš„å—å¤§å°å’Œé‡å 
2. **é«˜è´¨é‡åµŒå…¥**: ä½¿ç”¨åˆé€‚çš„åµŒå…¥æ¨¡å‹
3. **æ£€ç´¢ä¼˜åŒ–**: è°ƒæ•´æ£€ç´¢å‚æ•°å’Œç›¸ä¼¼åº¦é˜ˆå€¼
4. **æç¤ºå·¥ç¨‹**: è®¾è®¡æœ‰æ•ˆçš„æç¤ºæ¨¡æ¿
"""
        }
        
        # åˆ›å»ºä¸´æ—¶æ–‡ä»¶
        temp_files = []
        for filename, content in documents.items():
            temp_file = tempfile.NamedTemporaryFile(
                mode='w', 
                suffix='.md', 
                delete=False,
                encoding='utf-8'
            )
            temp_file.write(content)
            temp_file.close()
            temp_files.append(temp_file.name)
            print(f"  âœ… åˆ›å»ºæ–‡æ¡£: {filename}")
            
        print(f"ğŸ“„ å…±åˆ›å»º {len(temp_files)} ä¸ªç¤ºä¾‹æ–‡æ¡£")
        return temp_files
        
    def load_and_process_documents(self, file_paths: List[str]):
        """åŠ è½½å’Œå¤„ç†æ–‡æ¡£
        
        Args:
            file_paths: æ–‡æ¡£æ–‡ä»¶è·¯å¾„åˆ—è¡¨
        """
        print("\nğŸ“š åŠ è½½å’Œå¤„ç†æ–‡æ¡£...")
        
        try:
            # åŠ è½½æ–‡æ¡£
            documents = self.rag_service.load_documents(file_paths)
            print(f"  âœ… æˆåŠŸåŠ è½½ {len(documents)} ä¸ªæ–‡æ¡£")
            
            # åˆ‡åˆ†æ–‡æ¡£
            split_documents = self.rag_service.split_documents(documents)
            print(f"  âœ… æ–‡æ¡£åˆ‡åˆ†å®Œæˆï¼Œå…± {len(split_documents)} ä¸ªæ–‡æœ¬å—")
            
            # åˆ›å»ºå‘é‡å­˜å‚¨
            self.rag_service.create_vector_store(split_documents, self.collection_name)
            print(f"  âœ… å‘é‡å­˜å‚¨åˆ›å»ºå®Œæˆ: {self.collection_name}")
            
            # æ˜¾ç¤ºæ–‡æ¡£ç»Ÿè®¡
            stats = self.rag_service.get_stats()
            print(f"\nğŸ“Š æ–‡æ¡£å¤„ç†ç»Ÿè®¡:")
            print(f"  - åŸå§‹æ–‡æ¡£æ•°: {len(documents)}")
            print(f"  - æ–‡æœ¬å—æ•°: {len(split_documents)}")
            print(f"  - å¹³å‡å—å¤§å°: {stats.get('avg_chunk_size', 'N/A')}")
            
        except Exception as e:
            print(f"âŒ æ–‡æ¡£å¤„ç†å¤±è´¥: {e}")
            raise
            
    def setup_qa_components(self):
        """è®¾ç½®é—®ç­”ç»„ä»¶"""
        print("\nğŸ¤– è®¾ç½®é—®ç­”ç»„ä»¶...")
        
        try:
            # åŠ è½½å‘é‡å­˜å‚¨
            self.rag_service.load_vector_store(self.collection_name)
            
            # åˆ›å»ºä¸åŒç±»å‹çš„é—®ç­”ç»„ä»¶
            qa_types = ["simple", "retrieval", "conversational"]
            
            for qa_type in qa_types:
                qa_component = create_qa_component(
                    qa_type=qa_type,
                    retriever=self.rag_service.vector_store,
                    llm=self.rag_service.llm
                )
                self.qa_components[qa_type] = qa_component
                print(f"  âœ… {qa_type} é—®ç­”ç»„ä»¶åˆ›å»ºå®Œæˆ")
                
        except Exception as e:
            print(f"âŒ é—®ç­”ç»„ä»¶è®¾ç½®å¤±è´¥: {e}")
            raise
            
    def demo_basic_qa(self):
        """æ¼”ç¤ºåŸºç¡€é—®ç­”"""
        print("\n" + "="*50)
        print("ğŸ¯ åŸºç¡€é—®ç­”æ¼”ç¤º")
        print("="*50)
        
        questions = [
            "ä»€ä¹ˆæ˜¯äººå·¥æ™ºèƒ½ï¼Ÿ",
            "RAGæŠ€æœ¯çš„å·¥ä½œåŸç†æ˜¯ä»€ä¹ˆï¼Ÿ",
            "LangChainçš„æ ¸å¿ƒæ¦‚å¿µæœ‰å“ªäº›ï¼Ÿ",
            "æ·±åº¦å­¦ä¹ å’Œæœºå™¨å­¦ä¹ çš„å…³ç³»æ˜¯ä»€ä¹ˆï¼Ÿ"
        ]
        
        qa_component = self.qa_components["simple"]
        
        for i, question in enumerate(questions, 1):
            print(f"\nâ“ é—®é¢˜ {i}: {question}")
            
            try:
                result = qa_component.ask(
                    question=question,
                    k=3,
                    collection_name=self.collection_name
                )
                
                print(f"ğŸ’¡ å›ç­”: {result['answer']}")
                
                # æ˜¾ç¤ºæºæ–‡æ¡£
                if result.get('source_documents'):
                    print(f"\nğŸ“– å‚è€ƒæ¥æº ({len(result['source_documents'])} ä¸ª):")
                    for j, doc in enumerate(result['source_documents'][:2], 1):
                        content = doc.page_content if hasattr(doc, 'page_content') else str(doc)
                        preview = content[:100] + "..." if len(content) > 100 else content
                        print(f"  {j}. {preview}")
                        
            except Exception as e:
                print(f"âŒ é—®ç­”å¤±è´¥: {e}")
                
    def demo_conversational_qa(self):
        """æ¼”ç¤ºå¯¹è¯å¼é—®ç­”"""
        print("\n" + "="*50)
        print("ğŸ’¬ å¯¹è¯å¼é—®ç­”æ¼”ç¤º")
        print("="*50)
        
        conversation = [
            "ä»€ä¹ˆæ˜¯RAGæŠ€æœ¯ï¼Ÿ",
            "å®ƒæœ‰ä»€ä¹ˆä¼˜åŠ¿ï¼Ÿ",
            "åœ¨LangChainä¸­å¦‚ä½•å®ç°ï¼Ÿ",
            "èƒ½ç»™ä¸ªå…·ä½“çš„ä»£ç ç¤ºä¾‹å—ï¼Ÿ"
        ]
        
        qa_component = self.qa_components["conversational"]
        
        for i, question in enumerate(conversation, 1):
            print(f"\nğŸ‘¤ ç”¨æˆ· {i}: {question}")
            
            try:
                result = qa_component.ask(
                    question=question,
                    k=3,
                    collection_name=self.collection_name
                )
                
                print(f"ğŸ¤– åŠ©æ‰‹: {result['answer']}")
                
                # æ˜¾ç¤ºå¯¹è¯å†å²é•¿åº¦
                if hasattr(qa_component, 'get_conversation_stats'):
                    stats = qa_component.get_conversation_stats()
                    print(f"   (å¯¹è¯è½®æ¬¡: {stats.get('total_turns', i)})")
                    
            except Exception as e:
                print(f"âŒ å¯¹è¯å¤±è´¥: {e}")
                
    def demo_similarity_search(self):
        """æ¼”ç¤ºç›¸ä¼¼åº¦æœç´¢"""
        print("\n" + "="*50)
        print("ğŸ” ç›¸ä¼¼åº¦æœç´¢æ¼”ç¤º")
        print("="*50)
        
        queries = [
            "æœºå™¨å­¦ä¹ ç®—æ³•",
            "å‘é‡å­˜å‚¨æŠ€æœ¯",
            "æ–‡æ¡£å¤„ç†æ–¹æ³•"
        ]
        
        for query in queries:
            print(f"\nğŸ” æœç´¢: {query}")
            
            try:
                results = self.rag_service.similarity_search(query, k=3)
                
                print(f"ğŸ“‹ æ‰¾åˆ° {len(results)} ä¸ªç›¸å…³ç»“æœ:")
                for i, result in enumerate(results, 1):
                    content = result.get('content', str(result))
                    score = result.get('score', 'N/A')
                    preview = content[:150] + "..." if len(content) > 150 else content
                    print(f"  {i}. [ç›¸ä¼¼åº¦: {score}] {preview}")
                    
            except Exception as e:
                print(f"âŒ æœç´¢å¤±è´¥: {e}")
                
    def demo_interactive_mode(self):
        """äº¤äº’å¼é—®ç­”æ¨¡å¼"""
        print("\n" + "="*50)
        print("ğŸ® äº¤äº’å¼é—®ç­”æ¨¡å¼")
        print("="*50)
        print("è¾“å…¥é—®é¢˜è¿›è¡Œé—®ç­”ï¼Œè¾“å…¥ 'quit' é€€å‡º")
        
        qa_component = self.qa_components["conversational"]
        
        while True:
            try:
                question = input("\nğŸ‘¤ æ‚¨çš„é—®é¢˜: ").strip()
                
                if question.lower() in ['quit', 'exit', 'é€€å‡º', 'q']:
                    print("ğŸ‘‹ å†è§ï¼")
                    break
                    
                if not question:
                    continue
                    
                result = qa_component.ask(
                    question=question,
                    k=4,
                    collection_name=self.collection_name
                )
                
                print(f"ğŸ¤– å›ç­”: {result['answer']}")
                
                # æ˜¾ç¤ºæºæ–‡æ¡£æ•°é‡
                source_count = len(result.get('source_documents', []))
                if source_count > 0:
                    print(f"   (åŸºäº {source_count} ä¸ªç›¸å…³æ–‡æ¡£ç‰‡æ®µ)")
                    
            except KeyboardInterrupt:
                print("\nğŸ‘‹ å†è§ï¼")
                break
            except Exception as e:
                print(f"âŒ å¤„ç†å¤±è´¥: {e}")
                
    def cleanup_temp_files(self, file_paths: List[str]):
        """æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        
        Args:
            file_paths: ä¸´æ—¶æ–‡ä»¶è·¯å¾„åˆ—è¡¨
        """
        print("\nğŸ§¹ æ¸…ç†ä¸´æ—¶æ–‡ä»¶...")
        for file_path in file_paths:
            try:
                if os.path.exists(file_path):
                    os.unlink(file_path)
                    print(f"  âœ… åˆ é™¤: {file_path}")
            except Exception as e:
                print(f"  âš ï¸ åˆ é™¤å¤±è´¥: {file_path}, {e}")
                
    def run_demo(self, interactive: bool = False):
        """è¿è¡Œå®Œæ•´æ¼”ç¤º
        
        Args:
            interactive: æ˜¯å¦å¯ç”¨äº¤äº’æ¨¡å¼
        """
        print("ğŸš€ RAGç³»ç»Ÿæ¼”ç¤ºå¼€å§‹")
        print("="*60)
        
        temp_files = []
        
        try:
            # 1. è®¾ç½®RAGæœåŠ¡
            self.setup_rag_service()
            
            # 2. åˆ›å»ºç¤ºä¾‹æ–‡æ¡£
            temp_files = self.create_sample_documents()
            
            # 3. åŠ è½½å’Œå¤„ç†æ–‡æ¡£
            self.load_and_process_documents(temp_files)
            
            # 4. è®¾ç½®é—®ç­”ç»„ä»¶
            self.setup_qa_components()
            
            # 5. è¿è¡Œæ¼”ç¤º
            self.demo_basic_qa()
            self.demo_conversational_qa()
            self.demo_similarity_search()
            
            # 6. äº¤äº’æ¨¡å¼ï¼ˆå¯é€‰ï¼‰
            if interactive:
                self.demo_interactive_mode()
                
            print("\n" + "="*60)
            print("ğŸ‰ RAGç³»ç»Ÿæ¼”ç¤ºå®Œæˆï¼")
            print("\nğŸ“ æ¼”ç¤ºæ€»ç»“:")
            print("  âœ… æ–‡æ¡£åŠ è½½å’Œå¤„ç†")
            print("  âœ… åŸºç¡€é—®ç­”æŸ¥è¯¢")
            print("  âœ… å¯¹è¯å¼é—®ç­”")
            print("  âœ… ç›¸ä¼¼åº¦æœç´¢")
            if interactive:
                print("  âœ… äº¤äº’å¼é—®ç­”")
                
        except Exception as e:
            print(f"\nâŒ æ¼”ç¤ºè¿è¡Œå¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            
        finally:
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            if temp_files:
                self.cleanup_temp_files(temp_files)

def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description="RAGç³»ç»Ÿæ¼”ç¤º")
    parser.add_argument(
        "--interactive", 
        "-i", 
        action="store_true", 
        help="å¯ç”¨äº¤äº’å¼é—®ç­”æ¨¡å¼"
    )
    parser.add_argument(
        "--verbose", 
        "-v", 
        action="store_true", 
        help="æ˜¾ç¤ºè¯¦ç»†æ—¥å¿—"
    )
    
    args = parser.parse_args()
    
    # è®¾ç½®æ—¥å¿—çº§åˆ«
    if args.verbose:
        import logging
        logging.basicConfig(level=logging.INFO)
        
    # è¿è¡Œæ¼”ç¤º
    demo = RAGDemo()
    demo.run_demo(interactive=args.interactive)

if __name__ == "__main__":
    main()