# Day 6：向量数据库入门（Embedding + 存储）

## 📚 学习目标

掌握文本向量化、存储与搜索的核心技术，为构建RAG系统打下基础。

## 🎯 核心知识点

### 1. 什么是向量数据库？

向量数据库是专门用于存储和检索高维向量数据的数据库系统。在AI应用中，文本、图像等非结构化数据通过embedding模型转换为向量表示，然后存储在向量数据库中进行相似度搜索。

**简单理解：**
想象一下，传统数据库存储的是文字、数字等结构化数据，而向量数据库存储的是一串数字（向量），这些数字代表了文本的"语义特征"。比如：
- "苹果很甜" → [0.2, -0.1, 0.8, ...] （1536维向量）
- "水果味道好" → [0.3, -0.2, 0.7, ...] （相似的向量）

**核心概念详解：**

#### Embedding（嵌入）
- **定义**：将文本转换为数值向量的过程
- **举例**："今天天气很好" → [0.1, 0.3, -0.2, 0.8, ...]
- **特点**：语义相近的文本，其向量在高维空间中距离较近
- **维度**：OpenAI的embedding模型通常输出1536维向量

#### 相似度搜索
- **定义**：基于向量距离找到最相关的内容
- **常用算法**：
  - 余弦相似度：计算两个向量夹角的余弦值
  - 欧几里得距离：计算两点间的直线距离
  - 点积：向量内积运算
- **实际应用**：当用户问"天气怎么样"时，系统会找到与此最相似的已存储文档

#### Top-K检索
- **定义**：返回相似度最高的K个结果
- **举例**：用户查询返回最相关的5个文档片段
- **参数调优**：K值太小可能遗漏信息，太大可能引入噪音

### 2. OpenAI Embedding API 详解

#### 模型选择对比

| 模型 | 维度 | 价格 | 性能 | 推荐场景 |
|------|------|------|------|----------|
| `text-embedding-ada-002` | 1536 | 中等 | 良好 | 通用场景，稳定可靠 |
| `text-embedding-3-small` | 1536 | 较低 | 良好 | 成本敏感的项目 |
| `text-embedding-3-large` | 3072 | 较高 | 最佳 | 对精度要求高的场景 |

#### 实际使用示例

```python
# 基础调用示例
import openai

def get_embedding(text, model="text-embedding-3-small"):
    """获取文本的向量表示"""
    response = openai.Embedding.create(
        input=text,
        model=model
    )
    return response['data'][0]['embedding']

# 使用示例
text = "今天天气很好，适合出门散步"
vector = get_embedding(text)
print(f"向量维度: {len(vector)}")  # 输出: 1536
print(f"前5个数值: {vector[:5]}")   # 输出: [0.1, -0.2, 0.3, ...]
```

#### 使用场景详解

**1. 文档相似度搜索**
- 场景：在大量文档中找到与查询最相关的内容
- 实现：将所有文档向量化存储，查询时计算相似度

**2. 语义检索**
- 场景：用户用自然语言查询，系统理解语义返回结果
- 优势：不依赖关键词匹配，理解语义含义

**3. 推荐系统**
- 场景：基于用户历史行为推荐相似内容
- 实现：用户偏好向量化，推荐相似向量的内容

**4. 聚类分析**
- 场景：将相似文档自动分组
- 应用：新闻分类、客户反馈分析等

### 3. 向量数据库选型对比

| 数据库 | 特点 | 适用场景 | 优缺点 |
|--------|------|----------|--------|
| **FAISS** | Facebook开源，纯内存 | 原型开发、小规模应用 | ✅快速 ❌不持久化 |
| **ChromaDB** | 轻量级，易部署 | 中小型项目 | ✅简单易用 ❌扩展性有限 |
| **Weaviate** | 云原生，GraphQL API | 企业级应用 | ✅功能丰富 ❌复杂度高 |
| **Milvus** | 高性能，分布式 | 大规模生产环境 | ✅高性能 ❌运维复杂 |

## 🛠️ 实践环节

### 环境准备

#### 技术栈介绍

| 组件 | 作用 | 为什么选择 |
|------|------|------------|
| **LangChain** | AI应用开发框架 | 提供丰富的组件，简化开发流程 |
| **FAISS** | 向量存储和检索 | Facebook开源，性能优秀，易于使用 |
| **OpenAI Embedding** | 文本向量化 | 业界领先的embedding模型 |
| **FastAPI** | Web服务框架 | 现代化API框架，自动生成文档 |

#### 开发环境检查

```bash
# 1. 检查Python版本（需要3.8+）
python --version

# 2. 检查虚拟环境
which python  # 确保在项目虚拟环境中

# 3. 检查OpenAI API Key
echo $OPENAI_API_KEY  # 确保已设置环境变量
```

### 实战项目：构建简单问答系统

#### 系统架构详解

```
📝 文档准备 → 🔢 向量化 → 💾 存储到FAISS
                                    ↓
❓ 用户问题 → 🔢 问题向量化 → 🔍 相似度搜索
                                    ↓
📄 检索相关文档 → 🤖 LLM生成答案 → 📤 返回结果
```

#### 核心功能详解

**1. 文档向量化存储**
- 输入：原始文档（txt、pdf、markdown等）
- 处理：文档分块 → 向量化 → 存储索引
- 输出：可搜索的向量数据库

**2. 问题语义检索**
- 输入：用户自然语言问题
- 处理：问题向量化 → 相似度计算 → Top-K检索
- 输出：最相关的文档片段

**3. 基于检索结果的问答生成**
- 输入：用户问题 + 检索到的相关文档
- 处理：构建prompt → 调用LLM → 生成答案
- 输出：基于文档内容的准确答案

#### 项目文件结构

```
ai_rag_starter/
├── services/
│   ├── embedding_service.py      # 向量化服务
│   ├── vector_store_service.py    # 向量存储服务
│   └── qa_system.py              # 问答系统
├── examples/
│   ├── day6_demo.py              # 完整演示
│   └── day6_simple_example.py    # 简单示例
├── tests/
│   └── test_day6_vector_db.py    # 测试用例
└── data/
    └── vector_index/             # 向量索引存储
```

## 📝 详细学习步骤

### Step 1: 安装依赖包

#### 1.1 基础依赖安装
```bash
# 进入项目目录
cd /path/to/ai_rag_starter

# 激活虚拟环境
source venv/bin/activate  # macOS/Linux
# 或 venv\Scripts\activate  # Windows

# 安装向量数据库相关包
pip install faiss-cpu chromadb

# 验证安装
python -c "import faiss; print('FAISS安装成功')"
python -c "import chromadb; print('ChromaDB安装成功')"
```

#### 1.2 依赖包说明
- `faiss-cpu`：CPU版本的FAISS，适合开发和小规模应用
- `faiss-gpu`：GPU版本，适合大规模生产环境（需要CUDA）
- `chromadb`：轻量级向量数据库，可选使用

### Step 2: 创建Embedding服务

#### 2.1 服务设计思路
```python
# services/embedding_service.py 核心结构
class EmbeddingService:
    def __init__(self, api_key, model="text-embedding-3-small"):
        """初始化embedding服务"""
        pass
    
    def embed_text(self, text: str) -> List[float]:
        """单个文本向量化"""
        pass
    
    def embed_batch(self, texts: List[str]) -> List[List[float]]:
        """批量文本向量化（提高效率）"""
        pass
    
    def cosine_similarity(self, vec1, vec2) -> float:
        """计算余弦相似度"""
        pass
```

#### 2.2 实现要点
- **错误处理**：网络异常、API限流、无效输入等
- **重试机制**：指数退避策略，最大重试次数
- **批量处理**：提高API调用效率，降低成本
- **缓存机制**：避免重复计算相同文本的向量

#### 2.3 测试验证
```python
# 简单测试代码
embedding_service = EmbeddingService()
vector = embedding_service.embed_text("测试文本")
print(f"向量维度: {len(vector)}")  # 应该输出1536
```

### Step 3: 实现向量存储

#### 3.1 FAISS基础概念
- **Index（索引）**：存储向量的数据结构
- **IndexFlatL2**：暴力搜索，精确但慢
- **IndexIVFFlat**：倒排索引，快速但近似
- **IndexHNSW**：分层图索引，平衡速度和精度

#### 3.2 服务实现结构
```python
# services/vector_store_service.py 核心结构
class VectorStoreService:
    def __init__(self, dimension=1536):
        """初始化向量存储服务"""
        self.dimension = dimension
        self.index = None
        self.documents = []  # 存储原始文档
    
    def add_documents(self, documents, vectors):
        """添加文档和对应向量"""
        pass
    
    def search_similar(self, query_vector, k=5):
        """相似度搜索"""
        pass
    
    def save_index(self, path):
        """保存索引到磁盘"""
        pass
    
    def load_index(self, path):
        """从磁盘加载索引"""
        pass
```

#### 3.3 实现细节

**添加文档示例：**
```python
# 文档准备
documents = [
    "苹果是一种水果，味道很甜。",
    "香蕉富含钾元素，对健康有益。",
    "橙子含有丰富的维生素C。"
]

# 向量化
vectors = [embedding_service.embed_text(doc) for doc in documents]

# 存储到FAISS
vector_store.add_documents(documents, vectors)
```

**搜索示例：**
```python
# 用户查询
query = "什么水果比较甜？"
query_vector = embedding_service.embed_text(query)

# 搜索相似文档
results = vector_store.search_similar(query_vector, k=3)
for doc, score in results:
    print(f"相似度: {score:.3f}, 文档: {doc}")
```

### Step 4: 构建问答系统

#### 4.1 系统集成架构
```python
# services/qa_system.py 核心结构
class QASystem:
    def __init__(self, embedding_service, vector_store, llm_service):
        """初始化问答系统"""
        self.embedding_service = embedding_service
        self.vector_store = vector_store
        self.llm_service = llm_service
    
    def add_knowledge(self, documents):
        """添加知识库文档"""
        pass
    
    def answer_question(self, question, k=3):
        """回答问题"""
        # 1. 问题向量化
        # 2. 检索相关文档
        # 3. 构建prompt
        # 4. 调用LLM生成答案
        pass
```

#### 4.2 Prompt工程
```python
# 构建高质量的prompt
def build_qa_prompt(question, context_docs):
    context = "\n".join([f"文档{i+1}: {doc}" for i, doc in enumerate(context_docs)])
    
    prompt = f"""
基于以下文档内容回答问题，如果文档中没有相关信息，请说明无法回答。

相关文档：
{context}

问题：{question}

请提供准确、简洁的答案：
"""
    return prompt
```

#### 4.3 FastAPI接口实现
```python
# api/vector_qa.py
from fastapi import APIRouter

router = APIRouter()

@router.post("/qa/ask")
async def ask_question(request: QuestionRequest):
    """问答接口"""
    try:
        answer = qa_system.answer_question(request.question)
        return {"answer": answer, "status": "success"}
    except Exception as e:
        return {"error": str(e), "status": "error"}

@router.post("/qa/add_knowledge")
async def add_knowledge(request: KnowledgeRequest):
    """添加知识库"""
    qa_system.add_knowledge(request.documents)
    return {"message": "知识库更新成功", "status": "success"}
```

### Step 5: 测试与优化

#### 5.1 单元测试编写
```python
# tests/test_day6_vector_db.py
import pytest

class TestEmbeddingService:
    def test_embed_text(self):
        """测试文本向量化"""
        service = EmbeddingService()
        vector = service.embed_text("测试文本")
        assert len(vector) == 1536
        assert all(isinstance(x, float) for x in vector)
    
    def test_cosine_similarity(self):
        """测试余弦相似度计算"""
        service = EmbeddingService()
        vec1 = service.embed_text("苹果很甜")
        vec2 = service.embed_text("水果味道好")
        similarity = service.cosine_similarity(vec1, vec2)
        assert 0 <= similarity <= 1

class TestVectorStoreService:
    def test_add_and_search(self):
        """测试添加文档和搜索"""
        # 测试实现...
        pass
```

#### 5.2 性能优化策略

**1. 批量处理优化**
```python
# 批量向量化，减少API调用
def batch_embed_with_progress(texts, batch_size=100):
    results = []
    for i in range(0, len(texts), batch_size):
        batch = texts[i:i+batch_size]
        batch_vectors = embedding_service.embed_batch(batch)
        results.extend(batch_vectors)
        print(f"处理进度: {i+len(batch)}/{len(texts)}")
    return results
```

**2. 索引优化**
```python
# 根据数据量选择合适的索引类型
def create_optimized_index(dimension, num_docs):
    if num_docs < 1000:
        # 小数据量，使用精确搜索
        return faiss.IndexFlatL2(dimension)
    elif num_docs < 100000:
        # 中等数据量，使用IVF索引
        quantizer = faiss.IndexFlatL2(dimension)
        return faiss.IndexIVFFlat(quantizer, dimension, 100)
    else:
        # 大数据量，使用HNSW索引
        return faiss.IndexHNSWFlat(dimension, 32)
```

#### 5.3 准确率评估
```python
# 评估问答系统准确率
def evaluate_qa_system(test_questions, expected_answers):
    correct = 0
    total = len(test_questions)
    
    for question, expected in zip(test_questions, expected_answers):
        answer = qa_system.answer_question(question)
        # 使用语义相似度评估答案质量
        similarity = calculate_semantic_similarity(answer, expected)
        if similarity > 0.8:  # 阈值可调
            correct += 1
    
    accuracy = correct / total
    print(f"问答准确率: {accuracy:.2%}")
    return accuracy
```

## 🎓 学习成果检验

### 理论掌握检查清单

完成本章学习后，你应该能够回答以下问题：

**基础概念（必须掌握）**
- [ ] 什么是向量数据库？与传统数据库有什么区别？
- [ ] Embedding的作用是什么？为什么要将文本转换为向量？
- [ ] 余弦相似度是如何计算的？为什么适合文本相似度计算？
- [ ] Top-K检索中的K值如何选择？过大或过小有什么影响？

**技术实现（核心技能）**
- [ ] 如何调用OpenAI Embedding API获取文本向量？
- [ ] FAISS索引的创建、保存和加载流程是什么？
- [ ] 如何实现文档的批量向量化和存储？
- [ ] 问答系统的完整流程包括哪些步骤？

**实践应用（进阶能力）**
- [ ] 如何优化向量搜索的性能？
- [ ] 如何评估问答系统的准确率？
- [ ] 遇到API限流或网络错误如何处理？
- [ ] 如何设计合适的文档分块策略？

### 实际技能验证

**你将能够独立完成：**
- ✅ 使用OpenAI Embedding API进行文本向量化
- ✅ 构建和管理FAISS向量索引
- ✅ 实现基于语义的文档检索功能
- ✅ 集成LangChain组件构建RAG系统
- ✅ 开发完整的问答API服务
- ✅ 编写测试用例验证系统功能
- ✅ 优化系统性能和准确率

### 项目作品展示

学习完成后，你将拥有：
1. **完整的向量数据库服务** - 支持文档存储、检索和管理
2. **智能问答系统** - 基于语义检索的AI问答服务
3. **RESTful API接口** - 可直接部署的Web服务
4. **完善的测试套件** - 保证代码质量和功能正确性
5. **性能优化方案** - 适应不同规模的应用场景

## 📚 学习资源与参考资料

### 官方文档
- [OpenAI Embedding API文档](https://platform.openai.com/docs/guides/embeddings) - 官方API使用指南
- [FAISS官方文档](https://faiss.ai/) - Facebook AI相似性搜索库
- [LangChain向量存储指南](https://python.langchain.com/docs/modules/data_connection/vectorstores/) - 向量存储集成方案
- [ChromaDB快速开始](https://docs.trychroma.com/getting-started) - 轻量级向量数据库

### 常见问题解答

**Q1: 为什么选择FAISS而不是其他向量数据库？**
A: FAISS适合学习和原型开发，免费开源，性能优秀。生产环境可考虑Pinecone、Weaviate等托管服务。

**Q2: Embedding模型如何选择？**
A: 开发阶段推荐`text-embedding-3-small`，成本低效果好。生产环境可升级到`text-embedding-3-large`。

**Q3: 向量维度越高越好吗？**
A: 不一定。高维度提供更多信息但增加计算成本。1536维通常是性能和成本的良好平衡点。

**Q4: 如何处理中文文本？**
A: OpenAI的embedding模型天然支持中文，无需特殊处理。注意文本预处理（去除特殊字符、统一编码）。

**Q5: 向量搜索结果不准确怎么办？**
A: 检查文档分块策略、调整检索参数K值、优化prompt设计、考虑使用重排序模型。

### 进阶学习方向
**立即可学习：**
- **Day 7**：RAG（检索增强生成）高级实现
  - 文档分块策略优化
  - 混合检索（关键词+语义）
  - 结果重排序和过滤

**后续深入：**
- **Day 8**：多轮对话与记忆模块
  - 对话历史管理
  - 上下文感知检索
  - 个性化推荐

**扩展方向：**
- **向量数据库进阶**：学习Pinecone、Weaviate等云服务
- **Embedding优化**：微调embedding模型，提升领域适应性
- **系统架构**：分布式向量搜索，高并发处理
