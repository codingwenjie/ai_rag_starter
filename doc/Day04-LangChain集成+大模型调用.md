## ğŸ§  ç¬¬ä¸€æ­¥ï¼šLangChain åŸç†æ¦‚è¿°

### ä»€ä¹ˆæ˜¯ LangChainï¼Ÿ

LangChain æ˜¯ä¸€ä¸ªç”¨äºæ„å»ºè¯­è¨€æ¨¡å‹é©±åŠ¨åº”ç”¨çš„æ¡†æ¶ã€‚å®ƒå°† LLMï¼ˆå¦‚ OpenAI GPTã€Claudeã€Llamaï¼‰ä¸å·¥å…·é“¾ï¼ˆå¦‚æœç´¢ã€æ•°æ®åº“ã€APIï¼‰è¿›è¡Œç»„åˆï¼Œå¸®åŠ©å¼€å‘è€…æ›´å®¹æ˜“åœ°æ„å»º RAGã€Agent ç­‰å¤æ‚çš„åº”ç”¨ã€‚

### LangChain æ ¸å¿ƒç»„ä»¶

| æ¨¡å—       | åŠŸèƒ½                                                     |
| ---------- | -------------------------------------------------------- |
| **LLM**    | è°ƒç”¨è¯­è¨€æ¨¡å‹ï¼Œå¦‚ OpenAIã€Anthropicã€Claudeã€Local LLM ç­‰ |
| **Prompt** | æç¤ºè¯æ¨¡æ¿å¼•æ“ï¼ŒåŠ¨æ€æ„å»ºå¯¹è¯å†…å®¹                         |
| **Chains** | é“¾å¼é€»è¾‘æ‰§è¡Œæµï¼ˆè¾“å…¥ â†’ å¤„ç† â†’ è¾“å‡ºï¼‰                     |
| **Agents** | æ™ºèƒ½ä½“ï¼Œå…·æœ‰å†³ç­–èƒ½åŠ›ï¼Œèƒ½è°ƒç”¨å¤šä¸ªå·¥å…·æ¥å®Œæˆå¤æ‚ä»»åŠ¡       |
| **Memory** | è®°å¿†æ¨¡å—ï¼Œç”¨äºä¿å­˜å†å²å¯¹è¯ç­‰ä¸Šä¸‹æ–‡ä¿¡æ¯                   |
| **Tools**  | æ¥å…¥å¤–éƒ¨èƒ½åŠ›ï¼šæœç´¢ã€SQL æŸ¥è¯¢ã€å‘é‡åº“ã€Web API ç­‰         |

## ğŸ”§ ç¬¬äºŒæ­¥ï¼šå®æˆ˜æ¼”ç»ƒï¼ˆåœ¨ä½ çš„é¡¹ç›®ä¸­æ¥å…¥ LangChainï¼‰

### âœ… ç›®æ ‡ï¼š

1. æ¥å…¥ LangChain + OpenAI æ¨¡å‹
2. ç¼–å†™ä¸€ä¸ªç®€å•æ¥å£ï¼Œç”¨æˆ·æé—® â†’ è¿”å› LLM å›ç­”
3. ä½¿ç”¨ `.env` ç®¡ç† API å¯†é’¥
4. ä½¿ç”¨ Pydantic æ ¡éªŒè¾“å…¥å‚æ•°

------

## ğŸ“¦ å®‰è£…ä¾èµ–

ä½ å½“å‰é¡¹ç›®ç¯å¢ƒå·²å¯ç”¨ `uvicorn + FastAPI`ï¼Œåªéœ€å®‰è£…ï¼š

```
bash


å¤åˆ¶ç¼–è¾‘
pip install langchain openai
```

------

## ğŸ“ é¡¹ç›®ç»“æ„å˜æ›´ï¼ˆç®€è¦ï¼‰

```
bash


å¤åˆ¶ç¼–è¾‘
ai_rag_starter/
â”œâ”€â”€ main.py
â”œâ”€â”€ .env
â”œâ”€â”€ services/
â”‚   â””â”€â”€ llm_service.py   ğŸ‘ˆ æ–°å¢
â”œâ”€â”€ schemas/
â”‚   â””â”€â”€ llm_schema.py    ğŸ‘ˆ æ–°å¢
â””â”€â”€ ...
```

------

## ğŸ—‚ï¸ ç¬¬ä¸€æ­¥ï¼šé…ç½® `.env` å’ŒåŠ è½½

`.env` æ–‡ä»¶ï¼š

```
env


å¤åˆ¶ç¼–è¾‘
OPENAI_API_KEY=sk-xxx
```

åŠ è½½ç¯å¢ƒå˜é‡ï¼ˆmain.py ä¸­åŠ å…¥ï¼‰ï¼š

```
python


å¤åˆ¶ç¼–è¾‘
from dotenv import load_dotenv
load_dotenv()
```

------

## âœï¸ ç¬¬äºŒæ­¥ï¼šç¼–å†™è°ƒç”¨æ¨¡å‹æœåŠ¡ï¼ˆservices/llm_service.pyï¼‰

```
python


å¤åˆ¶ç¼–è¾‘
from langchain.chat_models import ChatOpenAI
import os

llm = ChatOpenAI(model_name="gpt-3.5-turbo", temperature=0.7, openai_api_key=os.getenv("OPENAI_API_KEY"))

def ask_llm(question: str) -> str:
    return llm.predict(question)
```

------

## âœ¨ ç¬¬ä¸‰æ­¥ï¼šå®šä¹‰è¯·æ±‚/å“åº” Schemaï¼ˆschemas/llm_schema.pyï¼‰

```
python


å¤åˆ¶ç¼–è¾‘
from pydantic import BaseModel

class QuestionRequest(BaseModel):
    question: str

class AnswerResponse(BaseModel):
    answer: str
```

------

## ğŸš€ ç¬¬å››æ­¥ï¼šç¼–å†™æ¥å£ï¼ˆmain.py ä¸­æ–°å¢ï¼‰

```
python


å¤åˆ¶ç¼–è¾‘
from fastapi import FastAPI
from schemas.llm_schema import QuestionRequest, AnswerResponse
from services.llm_service import ask_llm

app = FastAPI()

@app.post("/ask", response_model=AnswerResponse)
async def ask_question(data: QuestionRequest):
    answer = ask_llm(data.question)
    return AnswerResponse(answer=answer)
```

------

## ğŸ§ª æµ‹è¯•

ä½ å¯ä»¥ç”¨ curlã€Postman æˆ– FastAPI çš„ Swagger UIï¼š

```
http


å¤åˆ¶ç¼–è¾‘
POST http://localhost:8000/ask
Content-Type: application/json

{
  "question": "ä½ æ˜¯è°ï¼Ÿ"
}
```

